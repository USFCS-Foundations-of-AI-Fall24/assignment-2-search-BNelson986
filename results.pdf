Q2
----------------------------------
1-5
----------------------------------
BFS result:
States needed to reach goal:  83
(Location: battery
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'charge')

DFS result:
States needed to reach goal:  28
(Location: battery
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'move_to_battery', 9)


DLS result:
States needed to reach goal:  28
(Location: battery
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'move_to_battery', 9)

IDS result:
States needed to reach goal:  46
(Location: battery
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'charge', 7)

6.
-----------------------------------------
Sub problem solutions:

### BFS
get sample  result:
 (Location: sample
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: True
Charged? False, 'use_tool')
States needed to reach goal:  19


drop sample  result:
 (Location: station
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? False, 'drop_sample')
States needed to reach goal:  24


charge battery  result:
 (Location: battery
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'charge')
States needed to reach goal:  16


### DFS
get sample  result:
 (Location: sample
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: True
Charged? True, 'use_tool', 6)
States needed to reach goal:  19


drop sample  result:
 (Location: station
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'drop_tool', 6)
States needed to reach goal:  17


charge battery  result:
 (Location: battery
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'charge', 2)
States needed to reach goal:  6


### DLS
get sample  result:
 (Location: sample
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: True
Charged? True, 'use_tool', 6)
States needed to reach goal:  19


drop sample  result:
 (Location: station
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'drop_tool', 6)
States needed to reach goal:  17


charge battery  result:
 (Location: battery
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'charge', 2)
States needed to reach goal:  6


### IDS
get sample  result:
 (Location: sample
Holding Tool?: True
Sample Extracted?: True
Holding Sample?: True
Charged? False, 'use_tool', 3)
States needed to reach goal:  19


drop sample  result:
 (Location: station
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? False, 'drop_tool', 3)
States needed to reach goal:  9


charge battery  result:
 (Location: battery
Holding Tool?: False
Sample Extracted?: True
Holding Sample?: False
Charged? True, 'charge', 2)
States needed to reach goal:  6

----------------------------------------

Q3 A* Mars Planner:

Uniform Cost Search:
States needed to reach goal: 61

Straight Line Distance: 
States needed to reach goal: 49

-----------------------------------------

Q4 Constraints:
Antenna1: f1
Antenna2: f0
Antenna3: f2
Antenna4: f2
Antenna5: f1
Antenna6: f1
Antenna7: f0
Antenna8: f2
Antenna9: f0





Q5 Deep Blue vs AlphaZero

a) Some of the advances in engineering that lead to deep blues success were the development of a a single-chip chess search processor which enabled the machine to evaluate future moves with high speed, deep blue also incorporated a heavily parallel system to concurrently search through the tree of moves without creating a huge backlog. The parallelism developed for deep blue has the ability to be transferred to numerous other computing problems from graphics generation to neural networks and is very widely used in today’s world of computing. The custom chess chip that was developed for deep blue seems to be a one-off design that was created for a very specific problem and would probably not be overly useful outside of the original problem set.

b) The reasons behind AlphaZero being able to defeat stockfish with much less time has to do with the design and use of the neural network and how alphazero is able to learn and adjust its heuristics as the game plays out which allows it to eliminate positions that are determined as poor moves very early on in the evaluation of future states. This allows alphazero to instead focus on more important and productive possibilities. 
